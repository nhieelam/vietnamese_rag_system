import os
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.documents import Document

# 1. SETUP: Define your text data
# (In a real app, this text comes from your OCR results)
raw_text = """
ChÃ­nh sÃ¡ch an toÃ n lao Ä‘á»™ng nÄƒm 2024:
1. Táº¥t cáº£ nhÃ¢n viÃªn pháº£i Ä‘á»™i mÅ© báº£o há»™ khi vÃ o cÃ´ng trÆ°á»ng.
2. Thá»i gian lÃ m viá»‡c khÃ´ng quÃ¡ 8 tiáº¿ng má»—i ngÃ y.
3. BÃ¡o cÃ¡o tai náº¡n pháº£i Ä‘Æ°á»£c gá»­i trong vÃ²ng 24 giá».
4. Má»©c pháº¡t vi pháº¡m quy Ä‘á»‹nh an toÃ n lÃ  500.000 VNÄ.
"""

def create_vector_db():
    print("ğŸ”„ Starting to build Vector Database...")


    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50
    )
    
    docs = text_splitter.create_documents([raw_text])
    print(f"âœ… Split text into {len(docs)} chunks.")

    # 3. EMBEDDING: Load a model that understands Vietnamese
    # We use 'paraphrase-multilingual-MiniLM-L12-v2' which supports Vietnamese
    print("ğŸ”„ Loading Embedding Model (this may take a minute)...")
    embedding_model = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    )

    persist_directory = "./chroma_db"
    
    vector_db = Chroma.from_documents(
        documents=docs,
        embedding=embedding_model,
        persist_directory=persist_directory
    )
    
    print("Vector Database created successfully in './chroma_db'")
    return vector_db

if __name__ == "__main__":
    create_vector_db()